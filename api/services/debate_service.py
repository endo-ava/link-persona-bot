"""ãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆã‚µãƒ¼ãƒ“ã‚¹

è¨˜äº‹ã®ä¸»å¼µã«å¯¾ã™ã‚‹åè«–ç”Ÿæˆã¨ãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆå½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆã‚’æ‹…å½“ã—ã¾ã™ã€‚
"""

import logging
from typing import Optional

from api.config import get_settings
from api.exceptions import ArticleFetchError, LLMError
from api.fetcher import ArticleFetcher
from api.llm_client import LLMClient
from api.models.responses import DebateResponse, PersonaInfo
from api.persona_loader import PersonaLoader

logger = logging.getLogger(__name__)


class DebateService:
    """ãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹

    è¨˜äº‹ã®ä¸»å¼µã‚’æŠ½å‡ºã—ã€åè«–ã‚’ç”Ÿæˆã—ã€ãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆå½¢å¼ã§ã¾ã¨ã‚ã¾ã™ã€‚
    """

    def __init__(
        self,
        article_fetcher: ArticleFetcher,
        llm_client: LLMClient,
        persona_loader: PersonaLoader,
    ) -> None:
        """åˆæœŸåŒ–

        Args:
            article_fetcher: è¨˜äº‹å–å¾—ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
            llm_client: LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
            persona_loader: ãƒšãƒ«ã‚½ãƒŠãƒ­ãƒ¼ãƒ€ãƒ¼
        """
        self.article_fetcher = article_fetcher
        self.llm_client = llm_client
        self.persona_loader = persona_loader
        self.settings = get_settings()

    async def generate_debate(
        self,
        url: str,
        original_summary: Optional[str] = None,
        persona_id: Optional[str] = None,
        conversation_history: Optional[list[dict[str, str]]] = None,
    ) -> DebateResponse:
        """ãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹

        Args:
            url: è¨˜äº‹URLï¼ˆå°†æ¥çš„ã«ä½¿ç”¨äºˆå®šï¼‰
            original_summary: å…ƒã®è¦ç´„ï¼ˆçœç•¥å¯ï¼‰
            persona_id: ãƒšãƒ«ã‚½ãƒŠID
            conversation_history: ä¼šè©±å±¥æ­´

        Returns:
            ãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹

        Raises:
            ArticleFetchError: è¨˜äº‹å–å¾—å¤±æ•—
            LLMError: LLMå‘¼ã³å‡ºã—å¤±æ•—
        """
        logger.info(
            "Starting debate generation",
            extra={
                "url": url,
                "has_original_summary": original_summary is not None,
                "persona_id": persona_id,
                "conversation_history_count": len(conversation_history) if conversation_history else 0,
            }
        )

        try:
            # ãƒšãƒ«ã‚½ãƒŠã‚’å–å¾—
            persona = self.persona_loader.get_persona(persona_id) if persona_id else None
            if not persona:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒšãƒ«ã‚½ãƒŠã‚’ä½¿ç”¨
                all_personas = self.persona_loader.get_all_personas()
                persona = next(iter(all_personas.values())) if all_personas else None

            # ä¼šè©±å±¥æ­´ãŒã‚ã‚‹å ´åˆã¯ã€ãã‚Œã‚’åŸºã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ
            if conversation_history:
                response_text = await self._generate_conversation_response(
                    conversation_history=conversation_history,
                    persona=persona,
                )
            else:
                # å¾“æ¥ã®ãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼ˆè¨˜äº‹ãƒ™ãƒ¼ã‚¹ï¼‰
                response_text = await self._generate_article_debate(
                    url=url,
                    original_summary=original_summary,
                )

            logger.info(
                "Debate generated successfully",
                extra={"response_length": len(response_text)}
            )

            return DebateResponse(
                response=response_text,
                persona=PersonaInfo(
                    name=persona.name if persona else "ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ",
                    icon=persona.icon if persona else "ğŸ’¬",
                    color=persona.color if persona else 0x5865F2,
                    description=persona.description if persona else "è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ",
                ),
                context_used=len(conversation_history) if conversation_history else 0,
            )

        except ArticleFetchError:
            logger.error("Failed to fetch article", extra={"url": url}, exc_info=True)
            raise
        except LLMError:
            logger.error("LLM generation failed", extra={"url": url}, exc_info=True)
            raise
        except Exception as e:
            logger.error(
                "Unexpected error during debate generation",
                extra={"url": url, "error": str(e)},
                exc_info=True,
            )
            raise LLMError(
                "Failed to generate debate",
                details={"url": url, "error": str(e)}
            ) from e

    async def _generate_conversation_response(
        self,
        conversation_history: list[dict[str, str]],
        persona: Optional[object] = None,
    ) -> str:
        """ä¼šè©±å±¥æ­´ã‚’åŸºã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ

        Args:
            conversation_history: ä¼šè©±å±¥æ­´
            persona: ãƒšãƒ«ã‚½ãƒŠ

        Returns:
            ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆ
        """
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨­å®š
        system_prompt = (
            persona.get_system_message() if persona
            else "ã‚ãªãŸã¯è¦ªåˆ‡ã§å½¹ã«ç«‹ã¤ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
        )

        # ä¼šè©±å±¥æ­´ã‚’æ•´å½¢ã—ã¦LLMã«é€ä¿¡
        messages = [{"role": "system", "content": system_prompt}]
        messages.extend(conversation_history)

        try:
            response = await self.llm_client.chat_completion(messages=messages)
            return response.strip()
        except Exception as e:
            logger.error(
                "Failed to generate conversation response",
                extra={"error": str(e)},
                exc_info=True,
            )
            raise LLMError(
                "Failed to generate conversation response",
                details={"error": str(e)}
            ) from e

    async def _generate_article_debate(
        self,
        url: str,
        original_summary: Optional[str] = None,
    ) -> str:
        """è¨˜äº‹ãƒ™ãƒ¼ã‚¹ã®ãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆã‚’ç”Ÿæˆ

        Args:
            url: è¨˜äº‹URL
            original_summary: å…ƒã®è¦ç´„

        Returns:
            ãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆãƒ†ã‚­ã‚¹ãƒˆ
        """
        # è¨˜äº‹ã‚’å–å¾—
        article = await self.article_fetcher.fetch_article(url)
        logger.info(
            "Article fetched for debate",
            extra={
                "url": url,
                "title": article.get("title"),
                "content_length": len(article["content"]),
            }
        )

        # å…ƒã®ä¸»å¼µã‚’æŠ½å‡º
        if original_summary:
            original_stance = original_summary
        else:
            original_stance = await self._extract_stance(article)

        # åè«–ã‚’ç”Ÿæˆ
        counter_argument = await self._generate_counter_argument(original_stance)

        # ãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆã®ã¾ã¨ã‚ã‚’ç”Ÿæˆ
        debate_summary = await self._generate_debate_summary(
            original_stance,
            counter_argument
        )

        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        return f"""ã€å…ƒã®ä¸»å¼µã€‘
{original_stance.strip()}

ã€åè«–ã€‘
{counter_argument.strip()}

ã€ã¾ã¨ã‚ã€‘
{debate_summary.strip()}"""

    async def _extract_stance(self, article: dict) -> str:
        """è¨˜äº‹ã‹ã‚‰ä¸»å¼µã‚’æŠ½å‡º

        Args:
            article: è¨˜äº‹ãƒ‡ãƒ¼ã‚¿

        Returns:
            ä¸»å¼µãƒ†ã‚­ã‚¹ãƒˆ
        """
        stance_prompt = f"""ä»¥ä¸‹ã®è¨˜äº‹ã®ä¸»ãªä¸»å¼µã‚„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’{self.settings.summary_min_length}å­—ç¨‹åº¦ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚

è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«: {article.get('title', '(ã‚¿ã‚¤ãƒˆãƒ«ãªã—)')}
è¨˜äº‹æœ¬æ–‡:
{article['content'][:self.settings.article_max_length]}

ä¸»å¼µ:"""

        try:
            stance = await self.llm_client.chat_completion(
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯è¨˜äº‹ã®ä¸»å¼µã‚’å®¢è¦³çš„ã«åˆ†æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚"},
                    {"role": "user", "content": stance_prompt}
                ]
            )
            return stance.strip()
        except Exception as e:
            logger.error(
                "Failed to extract stance",
                extra={"error": str(e)},
                exc_info=True,
            )
            raise LLMError(
                "Failed to extract stance",
                details={"error": str(e)}
            ) from e

    async def _generate_counter_argument(self, original_stance: str) -> str:
        """åè«–ã‚’ç”Ÿæˆ

        Args:
            original_stance: å…ƒã®ä¸»å¼µ

        Returns:
            åè«–ãƒ†ã‚­ã‚¹ãƒˆ
        """
        counter_prompt = f"""ä»¥ä¸‹ã®ä¸»å¼µã«å¯¾ã—ã¦ã€åå¯¾ã®ç«‹å ´ã‹ã‚‰èª¬å¾—åŠ›ã®ã‚ã‚‹åè«–ã‚’{self.settings.summary_max_length}å­—ç¨‹åº¦ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

å…ƒã®ä¸»å¼µ:
{original_stance}

åè«–:"""

        try:
            counter = await self.llm_client.chat_completion(
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯æ‰¹åˆ¤çš„æ€è€ƒã‚’æŒã¤ãƒ‡ã‚£ãƒ™ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚å»ºè¨­çš„ãªåè«–ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"},
                    {"role": "user", "content": counter_prompt}
                ]
            )
            return counter.strip()
        except Exception as e:
            logger.error(
                "Failed to generate counter argument",
                extra={"error": str(e)},
                exc_info=True,
            )
            raise LLMError(
                "Failed to generate counter argument",
                details={"error": str(e)}
            ) from e

    async def _generate_debate_summary(
        self,
        original_stance: str,
        counter_argument: str
    ) -> str:
        """ãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆã®ã¾ã¨ã‚ã‚’ç”Ÿæˆ

        Args:
            original_stance: å…ƒã®ä¸»å¼µ
            counter_argument: åè«–

        Returns:
            ã¾ã¨ã‚ãƒ†ã‚­ã‚¹ãƒˆ
        """
        debate_summary_prompt = f"""ä»¥ä¸‹ã®2ã¤ã®ä¸»å¼µã«ã¤ã„ã¦ã€ç°¡æ½”ãªãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆã®ã¾ã¨ã‚ã‚’{self.settings.summary_min_length}å­—ç¨‹åº¦ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€å…ƒã®ä¸»å¼µã€‘
{original_stance}

ã€åè«–ã€‘
{counter_argument}

ã¾ã¨ã‚:"""

        try:
            summary = await self.llm_client.chat_completion(
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯ä¸­ç«‹çš„ãªç«‹å ´ã§ãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆã‚’ã¾ã¨ã‚ã‚‹å¸ä¼šè€…ã§ã™ã€‚"},
                    {"role": "user", "content": debate_summary_prompt}
                ]
            )
            return summary.strip()
        except Exception as e:
            logger.error(
                "Failed to generate debate summary",
                extra={"error": str(e)},
                exc_info=True,
            )
            raise LLMError(
                "Failed to generate debate summary",
                details={"error": str(e)}
            ) from e
